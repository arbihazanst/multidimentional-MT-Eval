{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odNXDOEqFh2y"
      },
      "outputs": [],
      "source": [
        "import os, json, re\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from math import ceil\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/MT/english to indonesia/Evaluator GPT-5-Chat/newResult\"  # or your Drive path if mounted\n",
        "OUTPUT_FOLDER = f\"{BASE_DIR}/eval_outputs\"\n",
        "DEBUG_FILE = f\"{OUTPUT_FOLDER}/AutomationMetric_Logs.json\"\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "API_KEY = \"<YOUR_KEY>\"\n",
        "ENDPOINT = \"https://<your-resource>.openai.azure.com/\"\n",
        "MODEL =  \"gpt-5-chat\"\n",
        "API_VER = \"2024-12-01-preview\"\n",
        "\n",
        "# ====== PROMPT (scores only; English -> Indonesian evaluation) ======\n",
        "PROMPT_HEADER = \"\"\"\n",
        "Evaluate the Indonesian translation of the English text below based on five criteria: Adequacy, Fluency, Morphosyntactic, Semantic, and Pragmatic. Use the scoring rubric from 1 to 5 for each criterion, as described in detail below. Assign only a numeric score for each aspect (no explanations).\n",
        "\n",
        "Scoring Rubrics:\n",
        "1. Adequacy: Does the Indonesian translation convey the same meaning as the English source sentence?\n",
        "- Scoring Guide:\n",
        "5: Complete transfer of meaning (accurate and all important information conveyed)\n",
        "4: Most meaning conveyed with minor omissions or errors\n",
        "3: Some parts are missing or incorrect, but some information still conveyed\n",
        "2: Major omissions or incorrect meaning, only small part of the information is conveyed\n",
        "1: Meaning largely incorrect or missing\n",
        "\n",
        "2. Fluency: How natural and grammatically correct is the Indonesian translation?\n",
        "- Scoring Guide:\n",
        "5: Fluent, natural, and grammatically correct\n",
        "4: Mostly fluent with minor grammatical issues or awkwardness\n",
        "3: Understandable, but noticeable grammatical errors\n",
        "2: Difficult to understand due to poor grammar or awkward phrasing\n",
        "1: Unintelligible due to major grammatical issues\n",
        "\n",
        "3. Morphosyntactic (Grammar, agreement, sentence structure, morphology):\n",
        "- Scoring Guide:\n",
        "5: No grammatical or syntactic errors. The sentence structure is fluent, and consistent with the source data. Morphological forms (e.g., tense, agreement, inflections) are fully accurate.\n",
        "4: Minor grammatical or syntactic issues that do not hinder comprehension. Word forms and sentence structure are mostly correct but slightly unnatural in places.\n",
        "3: Noticeable morphosyntactic errors that occasionally affect comprehension or fluency. May include agreement mistakes, awkward word order, different sentence structure, or wrong tense.\n",
        "2: Frequent errors in grammar and structure that hinder comprehension. The sentence structure differs significantly from the source data. Unnatural phrasing, tense confusion, or broken sentence patterns are common.\n",
        "1: Sentence is ungrammatical, fragmented, or unparseable. Morphosyntactic errors make it incomprehensible or entirely ungrammatical. The sentence structure is completely different from the source data.\n",
        "\n",
        "4. Semantic (Meaning preservation, omissions, mistranslations):\n",
        "- Scoring Guide:\n",
        "5: Full preservation of meaning. No omissions, distortions, or mistranslations. The translation conveys the same message as the source without deleting or adding additional words.\n",
        "4: Minor meaning shifts or vague expressions that slightly alter nuance but do not mislead. No omissions for verbs, subject, and object of the sentence.\n",
        "3: Partial meaning loss. Some ideas are omitted or inaccurately rendered, but core meaning is still recoverable with effort.\n",
        "2: Major meaning loss or distortion. Critical elements are missing, incorrect, or misleading. Intended message is mostly lost.\n",
        "1: Little semantic correspondence to the source. Mostly incorrect, irrelevant, or hallucinated content.\n",
        "\n",
        "5. Pragmatic (Tone, register, politeness, cultural/situational appropriateness):\n",
        "- Scoring Guide:\n",
        "5: Tone, register, and cultural fit are fully appropriate for the context. The translation sounds natural and is aligned with the speakers intent.\n",
        "4: Mostly appropriate tone and register. Slight mismatches (e.g., slightly too formal/informal), but do not cause misunderstanding or awkwardness.\n",
        "3: Inconsistent or ambiguous tone or formality. Some sections may sound awkward or misaligned with the source intent.\n",
        "2: Inappropriate tone or register for the context. Translation may sound offensive, robotic, or culturally inappropriate.\n",
        "1: Completely wrong pragmatic use. For example, overly rude, sarcastic instead of sincere, or completely mismatched social function.\n",
        "\n",
        "\n",
        "You will receive a list of examples. For each example, return a JSON object with:\n",
        "- \"row_id\": the given ID\n",
        "- \"scores\": { \"adequacy\": int, \"fluency\": int, \"morphosyntactic\": int, \"semantic\": int, \"pragmatic\": int }\n",
        "\n",
        "IMPORTANT OUTPUT FORMAT:\n",
        "Return a single JSON object with the key \"evaluations\" whose value is an array of the example results.\n",
        "Do not include any extra text, prose, or code fences—only valid JSON.\n",
        "\"\"\"\n",
        "\n",
        "def build_batch_prompt(batch_rows, source_col, translation_col):\n",
        "    \"\"\"\n",
        "    batch_rows: list of dicts with '_row_id' (string) and all original columns.\n",
        "    source_col: column containing English source text (e.g., 'source_en')\n",
        "    translation_col: column containing Indonesian translation (e.g., 'translation')\n",
        "    \"\"\"\n",
        "    examples = []\n",
        "    for r in batch_rows:\n",
        "        examples.append({\n",
        "            \"row_id\": str(r[\"_row_id\"]),\n",
        "            \"english_source\": str(r[source_col]),\n",
        "            \"indonesian_translation\": str(r[translation_col])\n",
        "        })\n",
        "    return PROMPT_HEADER + \"\\n\\n\" + json.dumps({\"examples\": examples}, ensure_ascii=False)\n",
        "\n",
        "def eval_csv_batched(\n",
        "    input_csv,\n",
        "    amount=None,\n",
        "    batch_size=20,\n",
        "    source_col=\"source_en\",        # <-- English source column\n",
        "    translation_col=\"translation\", # <-- Indonesian translation column\n",
        "    id_cols=(\"source_en\", \"translation\"),  # used to detect already-processed rows\n",
        "    save_debug=False,\n",
        "    print_debug=False\n",
        "):\n",
        "    if not os.path.exists(input_csv):\n",
        "        print(f\"❌ File not found: {input_csv}\")\n",
        "        return\n",
        "\n",
        "    output_csv = os.path.join(\n",
        "        OUTPUT_FOLDER,\n",
        "        os.path.basename(input_csv).replace(\".csv\", f\"_amount({amount})_batch({batch_size})_(GPT5)_NewRubric.csv\")\n",
        "    )\n",
        "\n",
        "    df = pd.read_csv(input_csv)\n",
        "    df.columns = df.columns.str.strip()\n",
        "    if amount not in (None, float(\"inf\")):\n",
        "        df = df[:amount]\n",
        "\n",
        "    # New metric columns to add\n",
        "    metric_cols = ['adequacy','fluency','morphosyntactic','semantic','pragmatic']\n",
        "\n",
        "    # Prepare/align output frame (keep all input columns + metrics)\n",
        "    if os.path.exists(output_csv):\n",
        "        out_df = pd.read_csv(output_csv)\n",
        "        # Drop legacy metrics if any slipped in\n",
        "        for legacy in ['bleu_score','meteor_score']:\n",
        "            if legacy in out_df.columns:\n",
        "                out_df = out_df.drop(columns=[legacy])\n",
        "        for c in df.columns:\n",
        "            if c not in out_df.columns:\n",
        "                out_df[c] = None\n",
        "        for c in metric_cols:\n",
        "            if c not in out_df.columns:\n",
        "                out_df[c] = None\n",
        "        out_df = out_df[[*df.columns, *metric_cols]]\n",
        "    else:\n",
        "        out_df = pd.DataFrame(columns=[*df.columns, *metric_cols])\n",
        "\n",
        "    # Helper: detect already processed rows by id_cols\n",
        "    def already_done(row):\n",
        "        if out_df.empty: return False\n",
        "        mask = pd.Series([True] * len(out_df))\n",
        "        for col in id_cols:\n",
        "            mask &= (out_df[col].astype(str) == str(row[col]))\n",
        "        return bool(mask.any())\n",
        "\n",
        "    # Build list of rows to evaluate; attach internal _row_id based on original index\n",
        "    rows = []\n",
        "    for idx, row in df.iterrows():\n",
        "        if not already_done(row):\n",
        "            d = row.to_dict()\n",
        "            d[\"_row_id\"] = str(idx)\n",
        "            rows.append(d)\n",
        "\n",
        "    if not rows:\n",
        "        print(\"✅ Nothing to do; all rows already evaluated.\")\n",
        "        return\n",
        "\n",
        "    client = AzureOpenAI(api_key=API_KEY, azure_endpoint=ENDPOINT, api_version=API_VER)\n",
        "\n",
        "    new_rows, debug_logs = [], []\n",
        "    total_batches = ceil(len(rows)/batch_size)\n",
        "\n",
        "    for b in tqdm(range(total_batches), desc=f\"Evaluating {os.path.basename(input_csv)}\"):\n",
        "        batch = rows[b*batch_size:(b+1)*batch_size]\n",
        "        prompt = build_batch_prompt(batch, source_col, translation_col)\n",
        "\n",
        "        try:\n",
        "            resp = client.chat.completions.create(\n",
        "                model=MODEL,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.0, top_p=0.0,\n",
        "                response_format={\"type\": \"json_object\"}\n",
        "            )\n",
        "            content = resp.choices[0].message.content.strip()\n",
        "            parsed = json.loads(content)\n",
        "            evals = parsed.get(\"evaluations\", [])\n",
        "        except Exception as e:\n",
        "            print(f\"Batch {b+1}/{total_batches} error: {e}\")\n",
        "            try:\n",
        "                m = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
        "                parsed = json.loads(m.group(0)) if m else {}\n",
        "                evals = parsed.get(\"evaluations\", [])\n",
        "            except Exception:\n",
        "                evals = []\n",
        "\n",
        "        # Map back by row_id\n",
        "        by_id = {str(it.get(\"row_id\")): it for it in evals}\n",
        "\n",
        "        for r in batch:\n",
        "            rid = str(r[\"_row_id\"])\n",
        "            it = by_id.get(rid)\n",
        "            if not it:\n",
        "                continue\n",
        "            scores = it.get(\"scores\", {})\n",
        "\n",
        "            # Keep only original input columns; do not persist _row_id\n",
        "            base = {c: r[c] for c in df.columns}\n",
        "\n",
        "            # Add metrics\n",
        "            for c in metric_cols:\n",
        "                base[c] = scores.get(c)\n",
        "\n",
        "            new_rows.append(base)\n",
        "\n",
        "        if save_debug or print_debug:\n",
        "            debug_logs.append({\n",
        "                \"batch_index\": b,\n",
        "                \"row_ids\": [str(r[\"_row_id\"]) for r in batch],\n",
        "                \"raw_response\": content if 'content' in locals() else None\n",
        "            })\n",
        "\n",
        "    if new_rows:\n",
        "        add_df = pd.DataFrame(new_rows)\n",
        "\n",
        "        # Ensure final columns: all original input columns + metric columns\n",
        "        for c in df.columns:\n",
        "            if c not in add_df.columns:\n",
        "                add_df[c] = None\n",
        "        for c in metric_cols:\n",
        "            if c not in add_df.columns:\n",
        "                add_df[c] = None\n",
        "        add_df = add_df[[*df.columns, *metric_cols]]\n",
        "\n",
        "        # Align existing out_df to the same columns/order\n",
        "        for c in add_df.columns:\n",
        "            if c not in out_df.columns:\n",
        "                out_df[c] = None\n",
        "        out_df = out_df[add_df.columns]\n",
        "\n",
        "        out_df = pd.concat([out_df, add_df], ignore_index=True)\n",
        "        out_df.to_csv(output_csv, index=False)\n",
        "        print(f\"✅ Saved: {output_csv}\")\n",
        "\n",
        "        # quick averages for this run\n",
        "        for col in metric_cols:\n",
        "            s = pd.to_numeric(add_df[col], errors='coerce').dropna()\n",
        "            print(f\"Avg {col}: {s.mean():.2f}\" if len(s) else f\"Avg {col}: n/a\")\n",
        "    else:\n",
        "        print(\"⚠️ No new evaluations were added.\")\n",
        "\n",
        "    if save_debug:\n",
        "        with open(DEBUG_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(debug_logs, f, indent=2, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c1aIaXUD6AG",
        "outputId": "9649791b-77a2-463a-8eb5-ff49bb31760a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating translated_with_gemma3_1b_EN_ID_0_1000_bleu_meteor.csv: 100%|██████████| 100/100 [04:24<00:00,  2.65s/it]\n",
            "/tmp/ipython-input-3955350803.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  out_df = pd.concat([out_df, add_df], ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: /content/drive/MyDrive/MT/english to indonesia/Evaluator GPT-5-Chat/newResult/eval_outputs/translated_with_gemma3_1b_EN_ID_0_1000_bleu_meteor_amount(1000)_batch(10)_(GPT5)_NewRubric.csv\n",
            "Avg adequacy: 4.08\n",
            "Avg fluency: 4.26\n",
            "Avg morphosyntactic: 4.26\n",
            "Avg semantic: 4.08\n",
            "Avg pragmatic: 4.40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating translated_with_llama3.2_3b_EN_ID_0_1000_bleu_meteor.csv: 100%|██████████| 100/100 [04:22<00:00,  2.62s/it]\n",
            "/tmp/ipython-input-3955350803.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  out_df = pd.concat([out_df, add_df], ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: /content/drive/MyDrive/MT/english to indonesia/Evaluator GPT-5-Chat/newResult/eval_outputs/translated_with_llama3.2_3b_EN_ID_0_1000_bleu_meteor_amount(1000)_batch(10)_(GPT5)_NewRubric.csv\n",
            "Avg adequacy: 3.75\n",
            "Avg fluency: 3.83\n",
            "Avg morphosyntactic: 3.83\n",
            "Avg semantic: 3.75\n",
            "Avg pragmatic: 4.06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating translated_with_qwen3_0.6b_EN_ID_0_1000_bleu_meteor.csv: 100%|██████████| 100/100 [04:44<00:00,  2.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: /content/drive/MyDrive/MT/english to indonesia/Evaluator GPT-5-Chat/newResult/eval_outputs/translated_with_qwen3_0.6b_EN_ID_0_1000_bleu_meteor_amount(1000)_batch(10)_(GPT5)_NewRubric.csv\n",
            "Avg adequacy: 2.74\n",
            "Avg fluency: 3.10\n",
            "Avg morphosyntactic: 3.10\n",
            "Avg semantic: 2.74\n",
            "Avg pragmatic: 3.25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/tmp/ipython-input-3955350803.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  out_df = pd.concat([out_df, add_df], ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "input_csv=[\"/content/drive/MyDrive/MT/english to indonesia/Evaluator GPT-5-Chat/data/translated_with_gemma3_1b_EN_ID_0_1000_bleu_meteor.csv\",\n",
        "           \"/content/drive/MyDrive/MT/english to indonesia/Evaluator GPT-5-Chat/data/translated_with_llama3.2_3b_EN_ID_0_1000_bleu_meteor.csv\",\n",
        "           \"/content/drive/MyDrive/MT/english to indonesia/Evaluator GPT-5-Chat/data/translated_with_qwen3_0.6b_EN_ID_0_1000_bleu_meteor.csv\"\n",
        "           ]\n",
        "\n",
        "for csv in input_csv:\n",
        "  eval_csv_batched(csv, amount=1000, batch_size=10, save_debug=True, print_debug=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-DGgUXuVpMm",
        "outputId": "c35b1ee7-afbf-456d-c4d6-74665510faf1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating translated_with_gemma3_1b_ted_end_id_2018_with_bleu.csv: 100%|██████████| 100/100 [03:50<00:00,  2.30s/it]\n",
            "/tmp/ipython-input-972317816.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  out_df = pd.concat([out_df, add_df], ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: /content/drive/MyDrive/MT/english to indonesia/Evaluator GPT-5-Chat/result/eval_outputs/translated_with_gemma3_1b_ted_end_id_2018_with_bleu_amount(1000)_batch(10)_(GPT5)_NewRubric.csv\n",
            "Avg adequacy: 4.10\n",
            "Avg fluency: 4.31\n",
            "Avg morphosyntactic: 4.31\n",
            "Avg semantic: 4.09\n",
            "Avg pragmatic: 4.44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating translated_with_llama3.2_1b_ted_end_id_2018_with_bleu.csv: 100%|██████████| 100/100 [03:50<00:00,  2.31s/it]\n",
            "/tmp/ipython-input-972317816.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  out_df = pd.concat([out_df, add_df], ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: /content/drive/MyDrive/MT/english to indonesia/Evaluator GPT-5-Chat/result/eval_outputs/translated_with_llama3.2_1b_ted_end_id_2018_with_bleu_amount(1000)_batch(10)_(GPT5)_NewRubric.csv\n",
            "Avg adequacy: 2.53\n",
            "Avg fluency: 2.66\n",
            "Avg morphosyntactic: 2.66\n",
            "Avg semantic: 2.53\n",
            "Avg pragmatic: 2.81\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating translated_with_qwen3_0.6b_ted_end_id_2018_with_bleu_clean_recomputed.csv: 100%|██████████| 100/100 [03:40<00:00,  2.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: /content/drive/MyDrive/MT/english to indonesia/Evaluator GPT-5-Chat/result/eval_outputs/translated_with_qwen3_0.6b_ted_end_id_2018_with_bleu_clean_recomputed_amount(1000)_batch(10)_(GPT5)_NewRubric.csv\n",
            "Avg adequacy: 2.75\n",
            "Avg fluency: 3.07\n",
            "Avg morphosyntactic: 3.07\n",
            "Avg semantic: 2.75\n",
            "Avg pragmatic: 3.24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/tmp/ipython-input-972317816.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  out_df = pd.concat([out_df, add_df], ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "input_csv=[\"/content/drive/MyDrive/MT/english to indonesia/bleu/translated_with_gemma3_1b_ted_end_id_2018_with_bleu.csv\",\n",
        "           \"/content/drive/MyDrive/MT/english to indonesia/bleu/translated_with_llama3.2_1b_ted_end_id_2018_with_bleu.csv\",\n",
        "           \"/content/drive/MyDrive/MT/english to indonesia/bleu/translated_with_qwen3_0.6b_ted_end_id_2018_with_bleu_clean_recomputed.csv\"\n",
        "           ]\n",
        "\n",
        "for csv in input_csv:\n",
        "  eval_csv_batched(csv, amount=1000, batch_size=10, save_debug=True, print_debug=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blB_op1CIrNd",
        "outputId": "91a74bd1-f892-4b17-8c23-23d5f75b97b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating translated_with_gemma3_1b_ted_end_id_2018_with_bleu.csv: 100%|██████████| 2/2 [00:04<00:00,  2.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: /content/drive/MyDrive/MT/english to indonesia/Evaluator GPT-5-Chat/Testing Batch/eval_outputs/translated_with_gemma3_1b_ted_end_id_2018_with_bleu_amount(20)_batch(10)_(GPT5)_NewRubric.csv\n",
            "Avg adequacy: 4.00\n",
            "Avg fluency: 4.55\n",
            "Avg morphosyntactic: 4.55\n",
            "Avg semantic: 4.00\n",
            "Avg pragmatic: 4.65\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/tmp/ipython-input-1680545715.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  out_df = pd.concat([out_df, add_df], ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "input_csv=\"/content/drive/MyDrive/MT/english to indonesia/bleu/translated_with_gemma3_1b_ted_end_id_2018_with_bleu.csv\"\n",
        "eval_csv_batched(input_csv, amount=20, batch_size=10, save_debug=True, print_debug=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3KiH4a5TG3y",
        "outputId": "c91eecab-9d29-4467-851a-48386b2d828f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating translated_with_gemma3_1b_ted_end_id_2018_with_bleu.csv: 100%|██████████| 2/2 [00:06<00:00,  3.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: /content/drive/MyDrive/MT/english to indonesia/Evaluator GPT-5-Chat/Testing Batch/eval_outputs/translated_with_gemma3_1b_ted_end_id_2018_with_bleu_amount20_batch(10)_(GPT5).csv\n",
            "Avg adequacy: 3.90\n",
            "Avg fluency: 4.50\n",
            "Avg morphosyntactic: 4.50\n",
            "Avg semantic: 3.90\n",
            "Avg pragmatic: 4.45\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/tmp/ipython-input-355969448.py:226: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  out_df = pd.concat([out_df, add_df], ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "input_csv=\"/content/drive/MyDrive/MT/english to indonesia/bleu/translated_with_gemma3_1b_ted_end_id_2018_with_bleu.csv\"\n",
        "eval_csv_batched(input_csv, amount=20, batch_size=10, save_debug=False, print_debug=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qs0JLO5SEYI",
        "outputId": "78042491-9922-4186-aabc-ea2d7da4d85d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating translated_with_gemma3_1b_ted_end_id_2018_with_bleu.csv: 100%|██████████| 4/4 [00:05<00:00,  1.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: /content/drive/MyDrive/MT/english to indonesia/Evaluator GPT-5-Chat/Testing Batch/eval_outputs/translated_with_gemma3_1b_ted_end_id_2018_with_bleu_amount20_batch(5)_(GPT5).csv\n",
            "Avg adequacy: 3.95\n",
            "Avg fluency: 4.30\n",
            "Avg morphosyntactic: 4.30\n",
            "Avg semantic: 3.95\n",
            "Avg pragmatic: 4.30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/tmp/ipython-input-355969448.py:226: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  out_df = pd.concat([out_df, add_df], ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "input_csv=\"/content/drive/MyDrive/MT/english to indonesia/bleu/translated_with_gemma3_1b_ted_end_id_2018_with_bleu.csv\"\n",
        "eval_csv_batched(input_csv, amount=20, batch_size=5, save_debug=False, print_debug=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtEC41-3cdpl",
        "outputId": "865b0b6b-fe45-4394-c67e-3c783001e647"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating translated_with_gemma3_1b_ted_end_id_2018_with_bleu.csv: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: /content/drive/MyDrive/MT/english to indonesia/Evaluator GPT-5-Chat/Testing Batch/eval_outputs/translated_with_gemma3_1b_ted_end_id_2018_with_bleu_amount20_batch(15)_(GPT5).csv\n",
            "Avg adequacy: 4.00\n",
            "Avg fluency: 4.40\n",
            "Avg morphosyntactic: 4.40\n",
            "Avg semantic: 4.00\n",
            "Avg pragmatic: 4.15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/tmp/ipython-input-355969448.py:226: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  out_df = pd.concat([out_df, add_df], ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "input_csv=\"/content/drive/MyDrive/MT/english to indonesia/bleu/translated_with_gemma3_1b_ted_end_id_2018_with_bleu.csv\"\n",
        "eval_csv_batched(input_csv, amount=20, batch_size=15, save_debug=False, print_debug=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9obn1c2acx1a",
        "outputId": "94faa488-185e-41ef-bb93-3e1a9f322caa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating translated_with_gemma3_1b_ted_end_id_2018_with_bleu.csv: 100%|██████████| 1/1 [00:04<00:00,  4.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: /content/drive/MyDrive/MT/english to indonesia/Evaluator GPT-5-Chat/Testing Batch/eval_outputs/translated_with_gemma3_1b_ted_end_id_2018_with_bleu_amount20_batch(20)_(GPT5).csv\n",
            "Avg adequacy: 4.05\n",
            "Avg fluency: 4.45\n",
            "Avg morphosyntactic: 4.45\n",
            "Avg semantic: 4.05\n",
            "Avg pragmatic: 4.20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/tmp/ipython-input-355969448.py:226: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  out_df = pd.concat([out_df, add_df], ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "input_csv=\"/content/drive/MyDrive/MT/english to indonesia/bleu/translated_with_gemma3_1b_ted_end_id_2018_with_bleu.csv\"\n",
        "eval_csv_batched(input_csv, amount=20, batch_size=20, save_debug=False, print_debug=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qrhHP7Jnz5q",
        "outputId": "6a2ab68a-b756-4562-8303-de1684aeb05f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating translated_with_gemma3_1b_ted_end_id_2018_with_bleu.csv: 100%|██████████| 1/1 [00:41<00:00, 41.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: /content/drive/MyDrive/MT/english to indonesia/Evaluator GPT-5-Chat/Testing Batch/eval_outputs/translated_with_gemma3_1b_ted_end_id_2018_with_bleu_amount(100)_batch(100)_(GPT5).csv\n",
            "Avg adequacy: 4.21\n",
            "Avg fluency: 4.31\n",
            "Avg morphosyntactic: 4.31\n",
            "Avg semantic: 4.21\n",
            "Avg pragmatic: 4.36\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/tmp/ipython-input-2505375157.py:226: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  out_df = pd.concat([out_df, add_df], ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "input_csv=\"/content/drive/MyDrive/MT/english to indonesia/bleu/translated_with_gemma3_1b_ted_end_id_2018_with_bleu.csv\"\n",
        "eval_csv_batched(input_csv, amount=100, batch_size=100, save_debug=False, print_debug=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
